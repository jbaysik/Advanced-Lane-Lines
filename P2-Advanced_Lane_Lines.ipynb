{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project 2: **Advanced Lane Lines** \n",
    "***\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "---\n",
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Camera Calibrations\n",
    "Camera calibration data generated in file [camera_calibration.ipynb](./camera_calibration.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load camera calibration data generated previously\n",
    "cam_cal = pickle.load( open('./cam_cal_data.p', 'rb' ) )\n",
    "mtx, dist = map(cam_cal.get, ('mtx', 'dist'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Perspective Transform Matrices\n",
    "Perspective transform data generated in file [lane_pipeline.ipynb](./lane_pipeline.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load perspective tranform matrices generated previously\n",
    "warp_data = pickle.load( open('./warp_data.p', 'rb' ) )\n",
    "M, Minv = map(warp_data.get, ('M', 'Minv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Functions\n",
    "Sobel thresholds for generating binary mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies Sobel x or y, then takes an absolute value and applies a threshold.\n",
    "def abs_sobel_thresh(img, orient='x', thresh_min=0, thresh_max=255):\n",
    "    # Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    sobel = None\n",
    "    if(orient == 'x'):\n",
    "        sobel = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "    # Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a mask of 1's where the scaled gradient magnitude \n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel > thresh_min) & (scaled_sobel < thresh_max)] = 1\n",
    "            # is > thresh_min and < thresh_max\n",
    "    # Return this mask as your binary_output image\n",
    "    return sxbinary\n",
    "\n",
    "# applies Sobel x and y, then computes the magnitude of the gradient and applies a threshold\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "    # Calculate the magnitude \n",
    "    abs_sobel = np.sqrt(np.square(sobelx) + np.square(sobely))\n",
    "    # Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scale_factor = np.max(abs_sobel)/255 \n",
    "    abs_sobel = (abs_sobel/scale_factor).astype(np.uint8) \n",
    "    # Create a binary mask where mag thresholds are met\n",
    "    # Return this mask as your binary_output image\n",
    "    binary_output = np.zeros_like(abs_sobel)\n",
    "    binary_output[(abs_sobel >= mag_thresh[0]) & (abs_sobel <= mag_thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "# applies Sobel x and y, then computes the direction of the gradient and applies a threshold.\n",
    "def dir_thresh(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.sqrt(np.square(sobelx))\n",
    "    abs_sobely = np.sqrt(np.square(sobely))\n",
    "    # Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    grad_dir = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    # Create a binary mask where direction thresholds are metbinary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output = np.zeros_like(grad_dir)\n",
    "    binary_output[(grad_dir >= thresh[0]) & (grad_dir <= thresh[1])] = 1\n",
    "    # Return this mask as your binary_output image\n",
    "    return binary_output\n",
    "\n",
    "# applies binary mask directly related to the value of the channel\n",
    "def binaryMask(img, thresh):\n",
    "    binary = np.zeros_like(img)\n",
    "    binary[(img > thresh[0]) & (img <= thresh[1])] = 1\n",
    "    return binary\n",
    "\n",
    "# combines a binary_mark on the r-channel (rgb) to various gradient thresholds applied to the l-channel (lab)\n",
    "def apply_combined_threshold(image):\n",
    "    \n",
    "    # use r-channel to reduce confusion with shadows\n",
    "    R = image[:,:,0]\n",
    "    R_binary = binaryMask(R, (220, 255))\n",
    "    \n",
    "    # convert to hls and isolate s-channel\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    # use s-channel to emphasis yellow lines in light shaded roads\n",
    "    l_channel = lab[:,:,0]\n",
    "    \n",
    "    grad_x = abs_sobel_thresh(l_channel, orient='x', thresh_min=20, thresh_max=120)\n",
    "    grad_y = abs_sobel_thresh(l_channel, orient='y', thresh_min=20, thresh_max=120)\n",
    "    grad_xy = np.zeros_like(grad_x)\n",
    "    grad_xy[(grad_x == 1) & (grad_y == 1)] = 1\n",
    "    \n",
    "    mag_grad = mag_thresh(l_channel, sobel_kernel=5, mag_thresh=(30, 150))\n",
    "    dir_grad = dir_thresh(l_channel, sobel_kernel=9, thresh=(0.7, 1.3))\n",
    "    sobel_binary = np.zeros_like(grad_x)\n",
    "    sobel_binary[(grad_xy == 1) | ((mag_grad == 1) & (dir_grad == 1))] = 1\n",
    "    \n",
    "    combined = np.zeros_like(R_binary)\n",
    "    combined[(R_binary == 1) | (sobel_binary == 1)] = 1\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for finding the lanes in a binary, warped image and outputting the plotted points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLaneLine(binary_warped, nwindows=9, margin=100,minpix=50):\n",
    "\n",
    "    # create historgram from sum across image pixels vertically\n",
    "    histogram = np.sum(binary_warped, axis=0)\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram for respective lanes\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # map all x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base# Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        # Find the four below boundaries of the window\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high) &\n",
    "                (nonzeroy >= win_y_low) & (nonzeroy < win_y_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzerox >= win_xright_low) & (nonzerox < win_xright_high) &\n",
    "                (nonzeroy >= win_y_low) & (nonzeroy < win_y_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If found > minpix pixels, recenter next window\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    return leftx, lefty, rightx, righty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other support functions for drawing lanes on top of the image, as well as calculating curvature and car position data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawLane(img, left_fitx, right_fitx, Minv):\n",
    "    # get y range for mapping x values\n",
    "    ploty = np.linspace(0, img.shape[0] - 1, img.shape[0])\n",
    "    \n",
    "    # create blank image to draw lanes\n",
    "    warped_lanes = np.zeros_like(img).astype(np.uint8)\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(warped_lanes, np.int_([pts]), (0,255, 0))\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    unwarped = cv2.warpPerspective(warped_lanes, Minv, (img.shape[1], img.shape[0])) \n",
    "    return cv2.addWeighted(img, 1, unwarped, 0.3, 0)\n",
    "\n",
    "def measureCurvatureAndCarPosition(x_points, y_points, img, ym_per_pix=30/720, xm_per_pix=3.7/700):    \n",
    "    # fit a second order polynomial in world space\n",
    "    line_fit = np.polyfit(y_points*ym_per_pix, x_points*xm_per_pix, 2)\n",
    "\n",
    "    # y space incompassess full top to bottom range image\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    \n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "\n",
    "    # Calculation of curvature radius in world space\n",
    "    line_curverad = ((1 + (2*line_fit[0]*y_eval*ym_per_pix + line_fit[1])**2)**1.5) / np.absolute(2*line_fit[0])\n",
    "    \n",
    "    #locate center of car based on center of image with respect to center of lane lines\n",
    "    y_max = img.shape[0]*ym_per_pix\n",
    "    x_max = img.shape[1]*xm_per_pix\n",
    "    car_center = x_max/2\n",
    "    \n",
    "    line_mid = line_fit[0]*y_max**2 + line_fit[1]*y_max + line_fit[2]\n",
    "    car_from_line = np.fabs(line_mid - car_center)\n",
    "    \n",
    "    return line_curverad, line_mid, car_from_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lane Class\n",
    "Class for maintaining lane stats and averaging for 'x' number of frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter for averaging frames\n",
    "n_frame_hyper = 5\n",
    "\n",
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        # average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None\n",
    "        #average y values of the fitted line over the last n iterations\n",
    "        self.besty = None    \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = None\n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None\n",
    "        #line mid-point in world space\n",
    "        self.line_mid = None\n",
    "    \n",
    "    # add new line data and update averages with latest lane found\n",
    "    def addNewLineData(self, img, x_points, y_points, n_frames = n_frame_hyper):\n",
    "        # update bestx with most recent points\n",
    "        self.bestx = x_points\n",
    "        self.besty = y_points\n",
    "\n",
    "        # calculate current fit\n",
    "        fit = np.polyfit(y_points, x_points, 2)\n",
    "        ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "        # separate x-values for ploting on top of image\n",
    "        fitx = fit[0]*ploty**2 + fit[1]*ploty + fit[2]\n",
    "        # copy to current\n",
    "        self.current_fit = np.copy(fitx)\n",
    "\n",
    "        # append newest points\n",
    "        self.recent_xfitted.append(fitx)\n",
    "\n",
    "        # keep 'n' newest frames\n",
    "        self.recent_xfitted = self.recent_xfitted[(0 - n_frames):]\n",
    "        \n",
    "        # calculate curvate of line's current fit\n",
    "        self.radius_of_curvature, self.line_mid, self.line_base_pos = measureCurvatureAndCarPosition(x_points, y_points, img)\n",
    "            \n",
    "    def getAverageFit(self, weight):\n",
    "        if len(self.recent_xfitted) == 0:\n",
    "            return self.current_fit\n",
    "        else:\n",
    "            return (weight * self.current_fit) + ((1-weight) * sum(self.recent_xfitted)/len(self.recent_xfitted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane Finding Pipeline\n",
    "---\n",
    "Each frame/image undergoes the following process:\n",
    "\n",
    "    undistort -> binary mask -> warp perspective -> find lanes -> draw lanes -> unwarp -> output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes image (or frame from video) and takes it through lane finding pipeline\n",
    "# output: image with drawing of lane, as well as lane curvature information and car position\n",
    "def process_image(img):\n",
    "    global left_line\n",
    "    global right_line\n",
    "    \n",
    "    # hyperparameter for calculating real word measurements\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # undistort image\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # apply threshold masks to create binary image\n",
    "    binary = apply_combined_threshold(undist)\n",
    "    # warp pespective to get top down view\n",
    "    img_size = (undist.shape[1], undist.shape[0])\n",
    "    binary_warped = cv2.warpPerspective(binary, M, img_size)\n",
    "    \n",
    "    # calculate lane line data points\n",
    "    leftx, lefty, rightx, righty = findLaneLine(binary_warped, nwindows=8, margin=120,minpix=75)\n",
    "    \n",
    "    left_line.addNewLineData(binary_warped, leftx, lefty)\n",
    "    right_line.addNewLineData(binary_warped, rightx, righty)\n",
    "    \n",
    "    # hyper parameter to weight most recent frame for averaging\n",
    "    weight = 0.5\n",
    "    \n",
    "    # calculate averages for lane data\n",
    "    left_fit_avg = left_line.getAverageFit(weight)\n",
    "    right_fit_avg = right_line.getAverageFit(weight)\n",
    "    \n",
    "    # add lane to img\n",
    "    lane_img = drawLane(undist, left_fit_avg, right_fit_avg, Minv)\n",
    "    \n",
    "    # calculate car position and curvature data\n",
    "    lane_curvature = (left_line.radius_of_curvature + right_line.radius_of_curvature)/2\n",
    "    lane_mid = (right_line.line_mid + left_line.line_mid)/2\n",
    "    car_position = binary_warped.shape[1]/2 * xm_per_pix\n",
    "    car_from_mid = np.fabs(lane_mid - car_position)\n",
    "    car_side = 'left' if (left_line.line_base_pos < right_line.line_base_pos) else 'right'\n",
    "    \n",
    "    # add text to image\n",
    "    cv2.putText(lane_img, 'Lane Curvature: {:04.2f}'.format(lane_curvature) + 'm',\n",
    "               (50,75), cv2.FONT_HERSHEY_DUPLEX, 1.5, (255, 255, 255), 2)\n",
    "    cv2.putText(lane_img, 'Car Position: {:04.3f}'.format(car_from_mid) + 'm ' + car_side + ' of center',\n",
    "               (50,125), cv2.FONT_HERSHEY_DUPLEX, 1.5, (255, 255, 255), 2)\n",
    "    \n",
    "    return lane_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Test Video\n",
    "---\n",
    "Use './project_video' to take through lane finding pipelin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./out_video.mp4\n",
      "[MoviePy] Writing video ./out_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████▉| 1260/1261 [07:20<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./out_video.mp4 \n",
      "\n",
      "Wall time: 7min 21s\n"
     ]
    }
   ],
   "source": [
    "left_line = Line()\n",
    "right_line = Line()\n",
    "\n",
    "# load project video for testing\n",
    "project_video = VideoFileClip('./project_video.mp4')\n",
    "\n",
    "# put video frames through pipeline\n",
    "out_video = project_video.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "\n",
    "# put together images and generate video\n",
    "%time out_video.write_videofile('./out_video.mp4', audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
